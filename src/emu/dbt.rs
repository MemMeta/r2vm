//! The code generated by this translator has a fixed stack layout, for easy handling of trap and exceptions.
//! If RSP is the original RSP before calling this function, then the stack should look like:
//! 
//! | Location | Description                                          |   |   |   |
//! |----------|------------------------------------------------------|---|---|---|
//! | [RSP-8]  | return address                                       |   |   |   |
//! | [RSP-16] | next translated PC, when executing a helper function |   |   |   |

use crate::x86::{Op as X86Op, Op::*, Register, Memory, Size, ConditionCode};
use crate::x86::builder::*;
use crate::riscv::Op;
use super::interp::{Context, SharedContext};
use std::convert::TryFrom;

pub struct DbtCompiler<'a> {
    pub buffer: &'a mut [u8],
    pub len: usize,
    pub interp: bool,
    minstret: u32,
    i_rel: usize,
    pc_rel: u64,
}

#[inline]
fn memory_of_register(reg: u8) -> Memory {
    (Register::RBP + reg as i32 * 8).qword()
}

#[inline]
fn memory_of_pc() -> Memory { 
    (Register::RBP + offset_of!(Context, pc) as i32).qword()
}

extern "C" {
    fn helper_yield();
    fn helper_step();
    fn helper_misalign();
    fn helper_translate_cache_miss();
    fn helper_icache_miss();
    fn helper_icache_wrong();
    fn helper_check_interrupt();
}

struct Label(usize);
enum PlaceHolder {
    Byte(usize),
    Dword(usize),
}

impl Drop for PlaceHolder {
    fn drop(&mut self) {
        panic!("placeholder left unpatched");
    }
}

impl<'a> DbtCompiler<'a> {
    pub fn new(code: &'a mut [u8]) -> DbtCompiler {
        DbtCompiler {
            buffer: code,
            len: 0,
            interp: false,
            minstret: 0,
            i_rel: 0,
            pc_rel: 0,
        }
    }

    fn emit(&mut self, op: X86Op) {
        crate::x86::encode(op, &mut |x| {
            self.buffer[self.len] = x;
            self.len += 1;
        });
    }

    fn emit_jcc_short(&mut self, cc: ConditionCode) -> PlaceHolder {
        self.emit(Jcc(0, cc));
        PlaceHolder::Byte(self.len)
    }

    fn emit_jcc_long(&mut self, cc: ConditionCode) -> PlaceHolder {
        self.emit(Jcc(0x80, cc));
        PlaceHolder::Dword(self.len)
    }

    fn emit_jmp_short(&mut self) -> PlaceHolder {
        self.emit(Jmp(Imm(0)));
        PlaceHolder::Byte(self.len)
    }

    fn label(&mut self) -> Label {
        Label(self.len)
    }

    fn patch(&mut self, place: PlaceHolder, label: Label) {
        match place {
            PlaceHolder::Byte(ptr) => {
                let offset = label.0 as isize - ptr as isize;
                self.buffer[ptr - 1] = i8::try_from(offset).unwrap() as u8
            }
            PlaceHolder::Dword(ptr) => {
                let offset = i32::try_from(label.0 as isize - ptr as isize).unwrap();
                self.buffer[ptr-4..ptr].copy_from_slice(&offset.to_le_bytes());
            }
        }
        std::mem::forget(place)
    }

    fn patch_absolute(&mut self, place: PlaceHolder, target: usize) {
        match place {
            PlaceHolder::Byte(_) => unimplemented!(),
            PlaceHolder::Dword(ptr) => {
                let offset = i32::try_from(target as isize - (self.buffer.as_ptr() as usize + ptr) as isize).unwrap();
                self.buffer[ptr-4..ptr].copy_from_slice(&offset.to_le_bytes());
            }
        }
        std::mem::forget(place)
    }

    // #region Helper functions
    //

    fn load_to_rax(&mut self, rs: u8) {
        if rs == 0 {
            self.emit(Xor(Reg(Register::EAX), OpReg(Register::EAX)));
            return
        }
        self.emit(Mov(Reg(Register::RAX), OpMem(memory_of_register(rs))));
    }

    fn store_from_rax(&mut self, rd: u8) {
        self.emit(Mov(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
    }

    fn load_to_eax(&mut self, rs: u8) {
        if rs == 0 {
            self.emit(Xor(Reg(Register::EAX), OpReg(Register::EAX)));
            return
        }
        self.emit(Mov(Reg(Register::EAX), OpMem(memory_of_register(rs).dword())));
    }

    fn store_from_eax(&mut self, rd: u8) {
        self.emit(Cdqe);
        self.store_from_rax(rd);
    }

    fn emit_move(&mut self, rd: u8, rs: u8) {
        if rd == 0 || rd == rs { return }
        if rs == 0 { return self.emit_load_imm(rd, 0) }

        self.emit(Mov(Reg(Register::RAX), OpMem(memory_of_register(rs))));
        self.emit(Mov(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
    }

    fn emit_move32(&mut self, rd: u8, rs: u8) {
        if rd == 0 { return }
        if rs == 0 { return self.emit_load_imm(rd, 0) }

        self.emit(Movsx(Register::RAX, Mem(memory_of_register(rs).dword())));
        self.emit(Mov(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
    }

    fn emit_load_imm(&mut self, rd: u8, imm: i64) {
        if rd == 0 { return }
        self.emit(Mov(Mem(memory_of_register(rd)), Imm(imm)));
    }

    /// We use EBX to convey message to helper_trap, which will adjust PC and INSTRET to reflect
    /// the precise location of exception.
    /// EBX encodes both the pc offset and the insret offset of the instruction relative to
    /// the end of the basic block.
    fn emit_set_ebx(&mut self) {
        let ebx = (self.i_rel as u32) << 16 | self.pc_rel as u32;
        self.emit(Mov(Reg(Register::EBX), Imm(ebx as i64)));
    }

    fn emit_helper_call(&mut self, helper: unsafe extern "C" fn()) {
        self.emit(Call(Imm(0x77777777)));
        let placeholder = PlaceHolder::Dword(self.len);
        self.patch_absolute(placeholder, helper as usize);
    }

    fn emit_helper_jmp(&mut self, helper: unsafe extern "C" fn()) {
        self.emit(Jmp(Imm(0x77777777)));
        let placeholder = PlaceHolder::Dword(self.len);
        self.patch_absolute(placeholder, helper as usize);
    }

    fn emit_step_call(&mut self, op: &Op) {
        // Functional-unit type instruction. Simply step through them.
        self.emit(Mov(Reg(Register::RSI), Imm(op as *const Op as usize as i64)));
        self.emit_set_ebx();
        self.emit_helper_call(helper_step);
    }

    //
    // #endregion

    fn emit_branch(&mut self, rs1: u8, rs2: u8, imm: i32, mut cc: ConditionCode) {
        if rs1 == rs2 {
            let result = match cc {
                ConditionCode::Equal |
                ConditionCode::GreaterEqual |
                ConditionCode::AboveEqual => true,
                _ => false,
            };
            if result {
                self.emit(Add(Mem(memory_of_pc()), Imm(imm.wrapping_sub(4) as i64)));
            }
            return;
        }

        // Compare and set flags.
        // If either operand is 0, it should be treated specially.
        if rs2 == 0 {
            self.emit(Cmp(Mem(memory_of_register(rs1)), Imm(0)));
        } else if rs1 == 0 {
            // Switch around condition code in this case.
            cc = cc.swap();
            self.emit(Cmp(Mem(memory_of_register(rs2)), Imm(0)));
        } else {
            self.emit(Mov(Reg(Register::RDX), OpMem(memory_of_register(rs1))));
            self.emit(Cmp(Reg(Register::RDX), OpMem(memory_of_register(rs2))));
        }

        let jcc_not = self.emit_jcc_long(!cc);

        self.emit(Add(Mem(memory_of_pc()), Imm(imm.wrapping_sub(4) as i64)));

        if cfg!(not(feature = "thread")) {
            self.emit_helper_call(helper_yield);
        }

        self.emit_interrupt_check();
        self.emit_chain_tail();

        let label_not = self.label();
        self.patch(jcc_not, label_not);
    }

    fn emit_jalr(&mut self, rd: u8, rs1: u8, imm: i32) {
        if rd != 0 {
            self.emit(Mov(Reg(Register::RDX), OpMem(memory_of_pc())));
        }
        self.load_to_rax(rs1);
        if imm != 0 {
            self.emit(Add(Reg(Register::RAX), Imm(imm as i64)));
        }
        self.emit(And(Reg(Register::RAX), Imm(!(1 as i64))));
        self.emit(Mov(Mem(memory_of_pc()), OpReg(Register::RAX)));
        if rd != 0 {
            self.emit(Mov(Mem(memory_of_register(rd)), OpReg(Register::RDX)));
        }
    }

    fn emit_jal(&mut self, rd: u8, imm: i32) {
        if rd != 0 {
            self.emit(Mov(Reg(Register::RAX), OpMem(memory_of_pc())));
        }
        self.emit(Add(Mem(memory_of_pc()), Imm(imm.wrapping_sub(4) as i64)));
        if rd != 0 {
            self.store_from_rax(rd);
        }
    }

    fn emit_icache_access(&mut self, off: u64) {
        let offset = offset_of!(Context, i_line);
        
        // RSI = addr
        self.emit(Mov(Reg(Register::RSI), OpMem(memory_of_pc())));
        self.emit(Sub(Reg(Register::RSI), Imm(off as i64)));

        // RCX = idx = addr >> CACHE_LINE_LOG2_SIZE
        self.emit(Mov(Reg(Register::RCX), OpReg(Register::RSI)));
        self.emit(Shr(Reg(Register::RCX), Imm(super::interp::CACHE_LINE_LOG2_SIZE as i64)));

        // EAX = (idx & 1023) * 16
        self.emit(Mov(Reg(Register::EAX), OpReg(Register::ECX)));
        self.emit(And(Reg(Register::EAX), Imm(1023)));
        self.emit(Shl(Reg(Register::EAX), Imm(4)));

        // RDX = ctx.line[(idx & 1023)].tag
        self.emit(Cmp(Reg(Register::RCX), OpMem(Register::RBP + Register::RAX + offset as i32)));

        self.emit(Jcc(5, ConditionCode::Equal));

        self.emit_helper_call(helper_icache_miss);
    }

    fn emit_chain_tail(&mut self) {
        let offset = offset_of!(Context, i_line);

        // RSI = addr
        self.emit(Mov(Reg(Register::RSI), OpMem(memory_of_pc())));

        // RCX = idx = addr >> CACHE_LINE_LOG2_SIZE
        self.emit(Mov(Reg(Register::RCX), OpReg(Register::RSI)));
        self.emit(Shr(Reg(Register::RCX), Imm(super::interp::CACHE_LINE_LOG2_SIZE as i64)));

        // EAX = (idx & 1023) * 16
        self.emit(Mov(Reg(Register::EAX), OpReg(Register::ECX)));
        self.emit(And(Reg(Register::EAX), Imm(1023)));
        self.emit(Shl(Reg(Register::EAX), Imm(4)));

        // RDX = ctx.line[(idx & 1023)].tag
        self.emit(Cmp(Reg(Register::RCX), OpMem(Register::RBP + Register::RAX + offset as i32)));
        self.emit(Jcc(10, ConditionCode::NotEqual));

        // Check if the current block is the intended block to execute
        self.emit(Xor(Reg(Register::RSI), OpMem(Register::RBP + Register::RAX + (offset + 8) as i32)));
        self.emit(Jmp(Imm(5)));

        self.emit_helper_call(helper_icache_miss);

        // Check if the current block is the intended block to execute
        self.emit(Mov(Reg(Register::RAX), Imm(0x100000000)));
        // 3 bytes
        self.emit(Cmp(Reg(Register::RAX), OpReg(Register::RSI)));
        // 2 bytes
        self.emit(Jcc(5, ConditionCode::Equal));

        self.emit_helper_call(helper_icache_wrong);
        self.emit(Jmp(Imm(0x7fffffff)));
    }

    fn emit_interrupt_check(&mut self) {
        let offset = offset_of!(Context, shared) + offset_of!(SharedContext, new_interrupts);
        self.emit(Cmp(Mem(Register::RBP + offset as i32), Imm(0)));
        let jcc_fin = self.emit_jcc_short(ConditionCode::Equal);

        self.emit_helper_jmp(helper_check_interrupt);

        let label_fin = self.label();
        self.patch(jcc_fin, label_fin);
    }

    /// Shared routine for generating load code. Note that this routine does not perform the
    /// actual load - it merely computes the address, translate to physical and leave it at RSI
    fn emit_load(&mut self, rs1: u8, imm: i32, size: Size) {
        self.minstret += 1;
        let offset = offset_of!(Context, line);
        
        // RSI = addr
        self.emit(Mov(Reg(Register::RSI), OpMem(memory_of_register(rs1))));
        if imm != 0 { self.emit(Add(Reg(Register::RSI), Imm(imm as i64))); }

        // Check for alignment
        let jcc_misalign = if size != Size::Byte {
            self.emit(Test(Reg(Register::ESI), Imm(size.bytes() as i64 - 1)));
            Some(self.emit_jcc_short(ConditionCode::NotEqual))
        } else { None };

        // RCX = idx = addr >> CACHE_LINE_LOG2_SIZE
        self.emit(Mov(Reg(Register::RCX), OpReg(Register::RSI)));
        self.emit(Shr(Reg(Register::RCX), Imm(super::interp::CACHE_LINE_LOG2_SIZE as i64)));

        // EAX = (idx & 1023) * 16
        self.emit(Mov(Reg(Register::EAX), OpReg(Register::ECX)));
        self.emit(And(Reg(Register::EAX), Imm(1023)));
        self.emit(Shl(Reg(Register::EAX), Imm(4)));

        // RDX = ctx.line[(idx & 1023)].tag >> 1
        self.emit(Mov(Reg(Register::RDX), OpMem(Register::RBP + Register::RAX + offset as i32)));
        self.emit(Shr(Reg(Register::RDX), Imm(1)));
        self.emit(Cmp(Reg(Register::RDX), OpReg(Register::RCX)));
        let jcc_miss = self.emit_jcc_short(ConditionCode::NotEqual);

        // RSI = ctx.line[(idx & 1023)].paddr ^ addr
        self.emit(Xor(Reg(Register::RSI), OpMem(Register::RBP + Register::RAX + (offset + 8) as i32)));
        let jmp_fin = self.emit_jmp_short();

        if size != Size::Byte {
            let label_misalign = self.label();
            self.patch(jcc_misalign.unwrap(), label_misalign);

            self.emit(Xor(Reg(Register::EDX), OpReg(Register::EDX)));
            self.emit_set_ebx();
            self.emit_helper_call(helper_misalign);
        }

        let label_miss = self.label();
        self.patch(jcc_miss, label_miss);

        self.emit(Xor(Reg(Register::EDX), OpReg(Register::EDX)));
        self.emit_set_ebx();
        self.emit_helper_call(helper_translate_cache_miss);

        let label_fin = self.label();
        self.patch(jmp_fin, label_fin);
    }

    fn emit_store(&mut self, rs1: u8, rs2: u8, imm: i32, size: Size) {
        self.minstret += 1;
        let offset = offset_of!(Context, line);

        // RSI = addr
        self.emit(Mov(Reg(Register::RSI), OpMem(memory_of_register(rs1))));
        if imm != 0 { self.emit(Add(Reg(Register::RSI), Imm(imm as i64))); }

        // Check for alignment
        let jcc_misalign = if size != Size::Byte {
            self.emit(Test(Reg(Register::ESI), Imm(size.bytes() as i64 - 1)));
            Some(self.emit_jcc_short(ConditionCode::NotEqual))
        } else { None };

        // RCX = idx = addr >> CACHE_LINE_LOG2_SIZE
        self.emit(Mov(Reg(Register::RCX), OpReg(Register::RSI)));
        self.emit(Shr(Reg(Register::RCX), Imm(super::interp::CACHE_LINE_LOG2_SIZE as i64)));

        // EAX = (idx & 1023) * 16
        self.emit(Mov(Reg(Register::EAX), OpReg(Register::ECX)));
        self.emit(And(Reg(Register::EAX), Imm(1023)));
        self.emit(Shl(Reg(Register::EAX), Imm(4)));

        // RCX = idx << 1
        self.emit(Add(Reg(Register::RCX), OpReg(Register::RCX)));
        self.emit(Cmp(Reg(Register::RCX), OpMem(Register::RBP + Register::RAX + offset as i32)));
        let jcc_miss = self.emit_jcc_short(ConditionCode::NotEqual);

        // RSI = ctx.line[(idx & 1023)].paddr ^ addr
        self.emit(Xor(Reg(Register::RSI), OpMem(Register::RBP + Register::RAX + (offset + 8) as i32)));
        let jmp_store = self.emit_jmp_short();

        if size != Size::Byte {
            let label_misalign = self.label();
            self.patch(jcc_misalign.unwrap(), label_misalign);

            self.emit(Mov(Reg(Register::EDX), Imm(1)));
            self.emit_set_ebx();
            self.emit_helper_call(helper_misalign);
        }

        let label_miss = self.label();
        self.patch(jcc_miss, label_miss);

        self.emit(Mov(Reg(Register::EDX), Imm(1)));
        self.emit_set_ebx();
        self.emit_helper_call(helper_translate_cache_miss);

        let label_store = self.label();
        self.patch(jmp_store, label_store);

        let reg = match size {
            Size::Byte => Register::DL,
            Size::Word => Register::DX,
            Size::Dword => Register::EDX,
            Size::Qword => Register::RDX,
        };
        let mut smem = memory_of_register(rs2);
        smem.size = size;
        let mut mem = Register::RSI + 0;
        mem.size = size;

        self.emit(Mov(Reg(reg), OpMem(smem)));
        self.emit(Mov(Mem(mem), OpReg(reg)));
    }

    // #region Base Opcode = OP-IMM
    //

    fn emit_addi(&mut self, rd: u8, rs1: u8, imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, imm as i64) }
        if imm == 0 { return self.emit_move(rd, rs1) }

        if rd == rs1 {
            return self.emit(Add(Mem(memory_of_register(rd)), Imm(imm as i64)))
        }

        self.emit(Mov(Reg(Register::RAX), OpMem(memory_of_register(rs1))));
        self.emit(Add(Reg(Register::RAX), Imm(imm as i64)));
        self.emit(Mov(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
    }

    fn emit_slli(&mut self, rd: u8, rs1: u8, imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if imm == 0 { return self.emit_move(rd, rs1) }

        if rd == rs1 {
            return self.emit(Shl(Mem(memory_of_register(rd)), Imm(imm as i64)))
        }

        self.emit(Mov(Reg(Register::RAX), OpMem(memory_of_register(rs1))));
        // For left shift by 1, we can use add instead.
        if imm == 1 {
            self.emit(Add(Reg(Register::RAX), OpReg(Register::RAX)))
        } else {
            self.emit(Shl(Reg(Register::RAX), Imm(imm as i64)))
        }

        self.emit(Mov(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
    }

    fn emit_slti(&mut self, rd: u8, rs1: u8, mut imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { self.emit_load_imm(rd, (imm > 0) as i64) }
        
        // When immediate is zero, this instruction basically determines the sign of the value in rs1. We can logical right
        // shift the value by 63 bits to achieve the same result.
        if imm == 0 {
            if rd == rs1 {
                self.emit(Shr(Mem(memory_of_register(rd)), Imm(63)));
            } else {
                self.load_to_rax(rs1);
                self.emit(Shr(Reg(Register::RAX), Imm(63)));
                self.store_from_rax(rd);
            }
        } else {
            // For positive numbers we decrease the value by one and the compare less equal. This can allow 1 more possible
            // immediate value to use shorter encoding.
            let mut cc = ConditionCode::Less;
            if imm > 0 {
                imm -= 1;
                cc = ConditionCode::LessEqual;
            }

            self.emit(Xor(Reg(Register::EAX), OpReg(Register::EAX)));
            self.emit(Cmp(Mem(memory_of_register(rs1)), Imm(imm as i64)));
            self.emit(Setcc(Reg(Register::AL), cc));
            self.store_from_rax(rd);
        }
    }

    fn emit_sltiu(&mut self, rd: u8, rs1: u8, mut imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { self.emit_load_imm(rd, (imm != 0) as i64) }
        if imm == 0 { self.emit_load_imm(rd, 0) }
        
        let cc = if imm > 0 {
            imm -= 1;
            if imm == 0 { ConditionCode::Equal } else { ConditionCode::BelowEqual }
        } else {
            if imm == -1 { ConditionCode::NotEqual } else { ConditionCode::Below }
        };

        self.emit(Xor(Reg(Register::EAX), OpReg(Register::EAX)));
        self.emit(Cmp(Mem(memory_of_register(rs1)), Imm(imm as i64)));
        self.emit(Setcc(Reg(Register::AL), cc));
        self.store_from_rax(rd);
    }

    fn emit_xori(&mut self, rd: u8, rs1: u8, imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, imm as i64) }
        if imm == 0 { return self.emit_move(rd, rs1) }

        if imm == -1 {
            if rd == rs1 {
                self.emit(Not(Mem(memory_of_register(rd))));
            } else {
                self.load_to_rax(rs1);
                self.emit(Not(Reg(Register::RAX)));
                self.store_from_rax(rd);
            }
        } else {
            if rd == rs1 {
                self.emit(Xor(Mem(memory_of_register(rd)), Imm(imm as i64)));
            } else {
                self.load_to_rax(rs1);
                self.emit(Xor(Reg(Register::RAX), Imm(imm as i64)));
                self.store_from_rax(rd);
            }
        }
    }

    fn emit_srli(&mut self, rd: u8, rs1: u8, imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if imm == 0 { return self.emit_move(rd, rs1) }

        if rd == rs1 {
            return self.emit(Shr(Mem(memory_of_register(rd)), Imm(imm as i64)))
        }

        self.emit(Mov(Reg(Register::RAX), OpMem(memory_of_register(rs1))));
        self.emit(Shr(Reg(Register::RAX), Imm(imm as i64)));
        self.emit(Mov(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
    }

    fn emit_srai(&mut self, rd: u8, rs1: u8, imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if imm == 0 { return self.emit_move(rd, rs1) }

        if rd == rs1 {
            return self.emit(Sar(Mem(memory_of_register(rd)), Imm(imm as i64)))
        }

        self.emit(Mov(Reg(Register::RAX), OpMem(memory_of_register(rs1))));
        self.emit(Sar(Reg(Register::RAX), Imm(imm as i64)));
        self.emit(Mov(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
    }

    fn emit_ori(&mut self, rd: u8, rs1: u8, imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, imm as i64) }
        if imm == 0 { return self.emit_move(rd, rs1) }
        if imm == -1 { return self.emit_load_imm(rd, -1) }

        if rd == rs1 {
            self.emit(Or(Mem(memory_of_register(rd)), Imm(imm as i64)));
        } else {
            self.load_to_rax(rs1);
            self.emit(Or(Reg(Register::RAX), Imm(imm as i64)));
            self.store_from_rax(rd);
        }
    }

    fn emit_andi(&mut self, rd: u8, rs1: u8, imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if imm == 0 { return self.emit_load_imm(rd, 0) }
        if imm == -1 { return self.emit_move(rd, rs1) }

        if rd == rs1 {
            self.emit(And(Mem(memory_of_register(rd)), Imm(imm as i64)));
        } else {
            self.load_to_rax(rs1);
            self.emit(And(Reg(Register::RAX), Imm(imm as i64)));
            self.store_from_rax(rd);
        }
    }

    //
    // #endregion

    // #region Base Opcode = OP-IMM-32
    //

    fn emit_addiw(&mut self, rd: u8, rs1: u8, imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, imm as i64) }
        if imm == 0 { return self.emit_move32(rd, rs1) }

        self.load_to_eax(rs1);
        self.emit(Add(Reg(Register::EAX), Imm(imm as i64)));
        self.store_from_eax(rd);
    }

    fn emit_slliw(&mut self, rd: u8, rs1: u8, imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if imm == 0 { return self.emit_move32(rd, rs1) }

        self.load_to_eax(rs1);
        // For left shift by 1, we can use add instead.
        if imm == 1 {
            self.emit(Add(Reg(Register::EAX), OpReg(Register::EAX)))
        } else {
            self.emit(Shl(Reg(Register::EAX), Imm(imm as i64)))
        }
        self.store_from_eax(rd);
    }

    fn emit_srliw(&mut self, rd: u8, rs1: u8, imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if imm == 0 { return self.emit_move32(rd, rs1) }

        self.load_to_eax(rs1);
        self.emit(Shr(Reg(Register::EAX), Imm(imm as i64)));
        self.store_from_eax(rd);
    }

    fn emit_sraiw(&mut self, rd: u8, rs1: u8, imm: i32) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if imm == 0 { return self.emit_move32(rd, rs1) }

        self.load_to_eax(rs1);
        self.emit(Sar(Reg(Register::EAX), Imm(imm as i64)));
        self.store_from_eax(rd);
    }

    //
    // #endregion

    // #region Base Opcode OP
    //

    fn emit_add(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_move(rd, rs2) }
        if rs2 == 0 { return self.emit_move(rd, rs1) }

        // Add one variable to itself can be efficiently implemented as an in-place shift.
        if rd == rs1 && rd == rs2 { return self.emit(Shl(Mem(memory_of_register(rd)), Imm(1))) }

        if rd == rs1 {
            self.load_to_rax(rs2);
            self.emit(Add(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
            return
        }

        if rd == rs2 {
            self.load_to_rax(rs1);
            self.emit(Add(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
            return
        }

        if rs1 == rs2 {
            self.load_to_rax(rs1);
            self.emit(Add(Reg(Register::RAX), OpReg(Register::RAX)));
            self.store_from_rax(rd);
            return
        }

        self.load_to_rax(rs1);
        self.emit(Add(Reg(Register::RAX), OpMem(memory_of_register(rs2))));
        self.store_from_rax(rd);
    }

    fn emit_sub(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs2 == 0 { return self.emit_move(rd, rs1) }
        if rs1 == rs2 { return self.emit_load_imm(rd, 0) }

        if rd == rs1 {
            self.load_to_rax(rs2);
            self.emit(Sub(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
            return
        }

        if rd == rs2 && rs1 == 0 {
            self.emit(Neg(Mem(memory_of_register(rd))));
            return
        }

        if rs1 == 0 {
            self.load_to_rax(rs2);
            self.emit(Neg(Reg(Register::RAX)));
            self.store_from_rax(rd);
            return
        }

        self.load_to_rax(rs1);
        self.emit(Sub(Reg(Register::RAX), OpMem(memory_of_register(rs2))));
        self.store_from_rax(rd);
    }

    fn emit_sll(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if rs2 == 0 { return self.emit_move(rd, rs1) }

        if rd == rs1 {
            self.emit(Mov(Reg(Register::CL), OpMem(memory_of_register(rs2).byte())));
            self.emit(Shl(Mem(memory_of_register(rd)), OpReg(Register::CL)));
            return
        }

        self.load_to_rax(rs1);
        self.emit(Mov(Reg(Register::CL), OpMem(memory_of_register(rs2).byte())));
        self.emit(Shl(Reg(Register::RAX), OpReg(Register::CL)));
        self.store_from_rax(rd);
    }

    fn emit_slt(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == rs2 { return self.emit_load_imm(rd, 0) }
        if rs1 == 0 {
            self.emit(Xor(Reg(Register::EAX), OpReg(Register::EAX)));
            self.emit(Cmp(Mem(memory_of_register(rs2)), Imm(0)));
            self.emit(Setcc(Reg(Register::AL), ConditionCode::Greater));
            self.store_from_rax(rd);
            return
        }

        // Similar to slti, shift by 63 bits yield the sign.
        if rs2 == 0 {
            if rd == rs1 {
                self.emit(Shr(Mem(memory_of_register(rd)), Imm(63)));
                return;
            }

            self.load_to_rax(rs1);
            self.emit(Shr(Reg(Register::RAX), Imm(63)));
            self.store_from_rax(rd);
            return
        }

        self.load_to_rax(rs1);
        self.emit(Cmp(Reg(Register::RAX), OpMem(memory_of_register(rs2))));
        self.emit(Setcc(Reg(Register::AL), ConditionCode::Less));
        self.emit(Movzx(Register::EAX, Reg(Register::AL)));
        self.store_from_rax(rd);
    }

    fn emit_sltu(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs2 == 0 || rs1 == rs2 { return self.emit_load_imm(rd, 0) }

        // snez
        if rs1 == 0 {
            self.emit(Xor(Reg(Register::EAX), OpReg(Register::EAX)));
            self.emit(Cmp(Mem(memory_of_register(rs2)), Imm(0)));
            self.emit(Setcc(Reg(Register::AL), ConditionCode::NotEqual));
            self.store_from_rax(rd);
            return
        }

        self.load_to_rax(rs1);
        self.emit(Cmp(Reg(Register::RAX), OpMem(memory_of_register(rs2))));
        self.emit(Setcc(Reg(Register::AL), ConditionCode::Below));
        self.emit(Movzx(Register::EAX, Reg(Register::AL)));
        self.store_from_rax(rd);
    }

    fn emit_xor(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_move(rd, rs2) }
        if rs2 == 0 { return self.emit_move(rd, rs1) }
        if rs1 == rs2 { return self.emit_load_imm(rd, 0) }

        if rd == rs1 {
            self.load_to_rax(rs2);
            self.emit(Xor(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
            return
        }

        if rd == rs2 {
            self.load_to_rax(rs1);
            self.emit(Xor(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
            return
        }

        self.load_to_rax(rs1);
        self.emit(Xor(Reg(Register::RAX), OpMem(memory_of_register(rs2))));
        self.store_from_rax(rd);
    }

    fn emit_srl(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if rs2 == 0 { return self.emit_move(rd, rs1) }

        if rd == rs1 {
            self.emit(Mov(Reg(Register::CL), OpMem(memory_of_register(rs2).byte())));
            self.emit(Shr(Mem(memory_of_register(rd)), OpReg(Register::CL)));
            return
        }

        self.load_to_rax(rs1);
        self.emit(Mov(Reg(Register::CL), OpMem(memory_of_register(rs2).byte())));
        self.emit(Shr(Reg(Register::RAX), OpReg(Register::CL)));
        self.store_from_rax(rd);
    }

    fn emit_sra(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if rs2 == 0 { return self.emit_move(rd, rs1) }

        if rd == rs1 {
            self.emit(Mov(Reg(Register::CL), OpMem(memory_of_register(rs2).byte())));
            self.emit(Sar(Mem(memory_of_register(rd)), OpReg(Register::CL)));
            return
        }

        self.load_to_rax(rs1);
        self.emit(Mov(Reg(Register::CL), OpMem(memory_of_register(rs2).byte())));
        self.emit(Sar(Reg(Register::RAX), OpReg(Register::CL)));
        self.store_from_rax(rd);
    }

    fn emit_or(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_move(rd, rs2) }
        if rs2 == 0 { return self.emit_move(rd, rs1) }
        if rs1 == rs2 { return self.emit_move(rd, rs1) }

        if rd == rs1 {
            self.load_to_rax(rs2);
            self.emit(Or(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
            return
        }

        if rd == rs2 {
            self.load_to_rax(rs1);
            self.emit(Or(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
            return
        }

        self.load_to_rax(rs1);
        self.emit(Or(Reg(Register::RAX), OpMem(memory_of_register(rs2))));
        self.store_from_rax(rd);
    }

    fn emit_and(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 || rs2 == 0 { return self.emit_load_imm(rd, 0) }
        if rs1 == rs2 { return self.emit_move(rd, rs1) }

        if rd == rs1 {
            self.load_to_rax(rs2);
            self.emit(And(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
            return
        }

        if rd == rs2 {
            self.load_to_rax(rs1);
            self.emit(And(Mem(memory_of_register(rd)), OpReg(Register::RAX)));
            return
        }

        self.load_to_rax(rs1);
        self.emit(And(Reg(Register::RAX), OpMem(memory_of_register(rs2))));
        self.store_from_rax(rd);
    }

    //
    // #endregion

    // #region Base Opcode OP-32
    //

    fn emit_addw(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_move32(rd, rs2) }
        if rs2 == 0 { return self.emit_move32(rd, rs1) }

        self.load_to_eax(rs1);
        if rs1 == rs2 {
            self.emit(Add(Reg(Register::EAX), OpReg(Register::EAX)));
        } else {
            self.emit(Add(Reg(Register::EAX), OpMem(memory_of_register(rs2).dword())));
        }
        self.store_from_eax(rd);
    }

    fn emit_subw(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs2 == 0 { return self.emit_move32(rd, rs1) }
        if rs1 == rs2 { return self.emit_load_imm(rd, 0) }

        if rs1 == 0 {
            self.load_to_eax(rs2);
            self.emit(Neg(Reg(Register::EAX)));
        } else {
            self.load_to_eax(rs1);
            self.emit(Sub(Reg(Register::EAX), OpMem(memory_of_register(rs2).dword())));
        }
        self.store_from_eax(rd);
    }

    fn emit_sllw(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if rs2 == 0 { return self.emit_move32(rd, rs1) }

        self.load_to_eax(rs1);
        self.emit(Mov(Reg(Register::CL), OpMem(memory_of_register(rs2).byte())));
        self.emit(Shl(Reg(Register::EAX), OpReg(Register::CL)));
        self.store_from_eax(rd);
    }

    fn emit_srlw(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if rs2 == 0 { return self.emit_move32(rd, rs1) }

        self.load_to_eax(rs1);
        self.emit(Mov(Reg(Register::CL), OpMem(memory_of_register(rs2).byte())));
        self.emit(Shr(Reg(Register::EAX), OpReg(Register::CL)));
        self.store_from_eax(rd);
    }

    fn emit_sraw(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 { return self.emit_load_imm(rd, 0) }
        if rs2 == 0 { return self.emit_move32(rd, rs1) }

        self.load_to_eax(rs1);
        self.emit(Mov(Reg(Register::CL), OpMem(memory_of_register(rs2).byte())));
        self.emit(Sar(Reg(Register::EAX), OpReg(Register::CL)));
        self.store_from_eax(rd);
    }

    //
    // #endregion

    // #region M-extension
    //

    fn emit_mul(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 || rs2 == 0 { return self.emit_load_imm(rd, 0) }

        self.load_to_rax(rs1);
        if rs1 == rs2 {
            self.emit(Imul2(Register::RAX, Reg(Register::RAX)));
        } else {
            self.emit(Imul2(Register::RAX, Mem(memory_of_register(rs2))));
        }
        self.store_from_rax(rd);
    }

    fn emit_mulh(&mut self, rd: u8, rs1: u8, rs2: u8, unsigned: bool) {
        if rd == 0 { return }
        if rs1 == 0 || rs2 == 0 { return self.emit_load_imm(rd, 0) }

        self.load_to_rax(rs1);
        let loc = if rs1 == rs2 { Reg(Register::RAX) } else { Mem(memory_of_register(rs2)) };
        if unsigned {
            self.emit(Mul(loc))
        } else {
            self.emit(Imul1(loc))
        }
        self.emit(Mov(Mem(memory_of_register(rd)), OpReg(Register::RDX)));
    }

    fn emit_mulhsu(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 || rs2 == 0 { return self.emit_load_imm(rd, 0) }

        // Load value to register and multiply.
        self.emit(Mov(Reg(Register::RCX), OpMem(memory_of_register(rs1))));
        self.emit(Mov(Reg(Register::RSI), OpMem(memory_of_register(rs2))));
        self.emit(Mov(Reg(Register::RAX), OpReg(Register::RCX)));
        self.emit(Mul(Reg(Register::RSI)));

        // Fix up negative by: if (rs1 < 0) rd = rd - rs2
        // Note that this is identical to rd = rd - (rs1 >>> 63) & rs2
        self.emit(Sar(Reg(Register::RCX), Imm(63)));;
        self.emit(And(Reg(Register::RCX), OpReg(Register::RSI)));
        self.emit(Sub(Reg(Register::RDX), OpReg(Register::RCX)));
        self.emit(Mov(Mem(memory_of_register(rd)), OpReg(Register::RDX)));
    }

    fn emit_mulw(&mut self, rd: u8, rs1: u8, rs2: u8) {
        if rd == 0 { return }
        if rs1 == 0 || rs2 == 0 { return self.emit_load_imm(rd, 0) }

        self.load_to_eax(rs1);
        if rs1 == rs2 {
            self.emit(Imul2(Register::EAX, Reg(Register::EAX)));
        } else {
            self.emit(Imul2(Register::EAX, Mem(memory_of_register(rs2).dword())));
        }
        self.store_from_eax(rd);
    }

    fn emit_div(&mut self, rd: u8, rs1: u8, rs2: u8, unsigned: bool, rem: bool) {
        if rd == 0 { return }
        
        // rs2 will be referenced directly, so we need to handle x0 specially.
        // x / 0 = -1, x % 0 = x
        if rs2 == 0 {
            if rem {
                self.emit_move(rd, rs1);
            } else {
                self.emit_load_imm(rd, -1);
            }
            return
        }

        // rs1 is loaded to rax, so no need to deal with x0
        self.load_to_rax(rs1);

        if unsigned {
            self.emit(Xor(Reg(Register::EDX), OpReg(Register::EDX)));
            self.emit(Div(Mem(memory_of_register(rs2))));
        } else {
            self.emit(Cqo);
            self.emit(Idiv(Mem(memory_of_register(rs2))));
        }

        if rem {
            self.emit(Mov(Mem(memory_of_register(rd)), OpReg(Register::RDX)));
        } else {
            self.store_from_rax(rd);
        }
    }

    fn emit_divw(&mut self, rd: u8, rs1: u8, rs2: u8, unsigned: bool, rem: bool) {
        if rd == 0 { return }
        
        // rs2 will be referenced directly, so we need to handle x0 specially.
        // x / 0 = -1, x % 0 = x
        if rs2 == 0 {
            if rem {
                self.emit_move32(rd, rs1);
            } else {
                self.emit_load_imm(rd, -1);
            }
            return
        }

        // rs1 is loaded to rax, so no need to deal with x0
        self.load_to_eax(rs1);

        if unsigned {
            self.emit(Xor(Reg(Register::EDX), OpReg(Register::EDX)));
            self.emit(Div(Mem(memory_of_register(rs2).dword())));
        } else {
            self.emit(Cdq);
            self.emit(Idiv(Mem(memory_of_register(rs2).dword())));
        }

        if rem {
            self.emit(Movsx(Register::RAX, Reg(Register::EDX)));
            self.store_from_rax(rd);
        } else {
            self.store_from_eax(rd);
        }
    }

    //
    // #endregion

    fn emit_op(&mut self, op: &crate::riscv::Op) {
        match *op {
            Op::Illegal => self.emit_step_call(op),
            /* LOAD */
            Op::Lb { rd, rs1, imm } => {
                self.emit_load(rs1, imm, Size::Byte);
                self.emit(Movsx(Register::RAX, Mem((Register::RSI + 0).byte())));
                self.store_from_rax(rd);
            }
            Op::Lh { rd, rs1, imm } => {
                self.emit_load(rs1, imm, Size::Word);
                self.emit(Movsx(Register::RAX, Mem((Register::RSI + 0).word())));
                self.store_from_rax(rd);
            }
            Op::Lw { rd, rs1, imm } => {
                self.emit_load(rs1, imm, Size::Dword);
                self.emit(Movsx(Register::RAX, Mem((Register::RSI + 0).dword())));
                self.store_from_rax(rd);
            }
            Op::Ld { rd, rs1, imm } => {
                self.emit_load(rs1, imm, Size::Qword);
                self.emit(Mov(Reg(Register::RAX), OpMem((Register::RSI + 0).qword())));
                self.store_from_rax(rd);
            }
            Op::Lbu { rd, rs1, imm } => {
                self.emit_load(rs1, imm, Size::Byte);
                self.emit(Movzx(Register::RAX, Mem((Register::RSI + 0).byte())));
                self.store_from_rax(rd);
            }
            Op::Lhu { rd, rs1, imm } => {
                self.emit_load(rs1, imm, Size::Word);
                self.emit(Movzx(Register::RAX, Mem((Register::RSI + 0).word())));
                self.store_from_rax(rd);
            }
            Op::Lwu { rd, rs1, imm } => {
                self.emit_load(rs1, imm, Size::Dword);
                self.emit(Mov(Reg(Register::EAX), OpMem((Register::RSI + 0).dword())));
                self.store_from_rax(rd);
            }
            /* OP-IMM */
            Op::Addi { rd, rs1, imm } => self.emit_addi(rd, rs1, imm),
            Op::Slli { rd, rs1, imm } => self.emit_slli(rd, rs1, imm),
            Op::Slti { rd, rs1, imm } => self.emit_slti(rd, rs1, imm),
            Op::Sltiu { rd, rs1, imm } => self.emit_sltiu(rd, rs1, imm),
            Op::Xori { rd, rs1, imm } => self.emit_xori(rd, rs1, imm),
            Op::Srli { rd, rs1, imm } => self.emit_srli(rd, rs1, imm),
            Op::Srai { rd, rs1, imm } => self.emit_srai(rd, rs1, imm),
            Op::Ori { rd, rs1, imm } => self.emit_ori(rd, rs1, imm),
            Op::Andi { rd, rs1, imm } => self.emit_andi(rd, rs1, imm),
            /* MISC-MEM */
            Op::Fence => self.emit(Mfence),
            Op::FenceI => self.emit_step_call(op),
            /* OP-IMM-32 */
            Op::Addiw { rd, rs1, imm } => self.emit_addiw(rd, rs1, imm),
            Op::Slliw { rd, rs1, imm } => self.emit_slliw(rd, rs1, imm),
            Op::Srliw { rd, rs1, imm } => self.emit_srliw(rd, rs1, imm),
            Op::Sraiw { rd, rs1, imm } => self.emit_sraiw(rd, rs1, imm),
            /* STORE */
            Op::Sb { rs1, rs2, imm } => self.emit_store(rs1, rs2, imm, Size::Byte),
            Op::Sh { rs1, rs2, imm } => self.emit_store(rs1, rs2, imm, Size::Word),
            Op::Sw { rs1, rs2, imm } => self.emit_store(rs1, rs2, imm, Size::Dword),
            Op::Sd { rs1, rs2, imm } => self.emit_store(rs1, rs2, imm, Size::Qword),
            /* OP */
            Op::Add { rd, rs1, rs2 } => self.emit_add(rd, rs1, rs2),
            Op::Sub { rd, rs1, rs2 } => self.emit_sub(rd, rs1, rs2),
            Op::Sll { rd, rs1, rs2 } => self.emit_sll(rd, rs1, rs2),
            Op::Slt { rd, rs1, rs2 } => self.emit_slt(rd, rs1, rs2),
            Op::Sltu { rd, rs1, rs2 } => self.emit_sltu(rd, rs1, rs2),
            Op::Xor { rd, rs1, rs2 } => self.emit_xor(rd, rs1, rs2),
            Op::Srl { rd, rs1, rs2 } => self.emit_srl(rd, rs1, rs2),
            Op::Sra { rd, rs1, rs2 } => self.emit_sra(rd, rs1, rs2),
            Op::Or { rd, rs1, rs2 } => self.emit_or(rd, rs1, rs2),
            Op::And { rd, rs1, rs2 } => self.emit_and(rd, rs1, rs2),
            /* LUI */
            Op::Lui { rd, imm } => self.emit_load_imm(rd, imm as i64),
            /* OP-32 */
            Op::Addw { rd, rs1, rs2 } => self.emit_addw(rd, rs1, rs2),
            Op::Subw { rd, rs1, rs2 } => self.emit_subw(rd, rs1, rs2),
            Op::Sllw { rd, rs1, rs2 } => self.emit_sllw(rd, rs1, rs2),
            Op::Srlw { rd, rs1, rs2 } => self.emit_srlw(rd, rs1, rs2),
            Op::Sraw { rd, rs1, rs2 } => self.emit_sraw(rd, rs1, rs2),
            /* AUIPC */
            Op::Auipc { rd, imm } => {
                self.emit(Mov(Reg(Register::RAX), OpMem(memory_of_pc())));
                self.emit(Add(Reg(Register::RAX), Imm(imm as i64 - 4)));
                self.store_from_rax(rd);
            }
            /* BRANCH */
            Op::Beq { rs1, rs2, imm } => self.emit_branch(rs1, rs2, imm, ConditionCode::Equal),
            Op::Bne { rs1, rs2, imm } => self.emit_branch(rs1, rs2, imm, ConditionCode::NotEqual),
            Op::Blt { rs1, rs2, imm } => self.emit_branch(rs1, rs2, imm, ConditionCode::Less),
            Op::Bge { rs1, rs2, imm } => self.emit_branch(rs1, rs2, imm, ConditionCode::GreaterEqual),
            Op::Bltu { rs1, rs2, imm } => self.emit_branch(rs1, rs2, imm, ConditionCode::Below),
            Op::Bgeu { rs1, rs2, imm } => self.emit_branch(rs1, rs2, imm, ConditionCode::AboveEqual),
            /* JALR */
            Op::Jalr { rd, rs1, imm } => self.emit_jalr(rd, rs1, imm),
            /* JAL */
            Op::Jal { rd, imm } => self.emit_jal(rd, imm),
            /* SYSTEM */
            Op::Ecall |
            Op::Ebreak |
            Op::Csrrw {..} |
            Op::Csrrs {..} |
            Op::Csrrc {..} |
            Op::Csrrwi {..} |
            Op::Csrrsi {..} |
            Op::Csrrci {..} => self.emit_step_call(op),

            /* F-extension */
            Op::Flw {..} |
            Op::Fsw {..} |
            Op::FaddS {..} |
            Op::FsubS {..} |
            Op::FmulS {..} |
            Op::FdivS {..} |
            Op::FsqrtS {..} |
            Op::FsgnjS {..} |
            Op::FsgnjnS {..} |
            Op::FsgnjxS {..} |
            Op::FminS {..} |
            Op::FmaxS {..} |
            Op::FcvtWS {..} |
            Op::FcvtWuS {..} |
            Op::FcvtLS {..} |
            Op::FcvtLuS {..} |
            Op::FmvXW {..} |
            Op::FclassS {..} |
            Op::FeqS {..} |
            Op::FltS {..} |
            Op::FleS {..} |
            Op::FcvtSW {..} |
            Op::FcvtSWu {..} |
            Op::FcvtSL {..} |
            Op::FcvtSLu {..} |
            Op::FmvWX {..} |
            Op::FmaddS {..} |
            Op::FmsubS {..} |
            Op::FnmsubS {..} |
            Op::FnmaddS {..} |
            /* D-extension */
            Op::Fld {..} |
            Op::Fsd {..} |
            Op::FaddD {..} |
            Op::FsubD {..} |
            Op::FmulD {..} |
            Op::FdivD {..} |
            Op::FsqrtD {..} |
            Op::FsgnjD {..} |
            Op::FsgnjnD {..} |
            Op::FsgnjxD {..} |
            Op::FminD {..} |
            Op::FmaxD {..} |
            Op::FcvtSD {..} |
            Op::FcvtDS {..} |
            Op::FcvtWD {..} |
            Op::FcvtWuD {..} |
            Op::FcvtLD {..} |
            Op::FcvtLuD {..} |
            Op::FmvXD {..} |
            Op::FclassD {..} |
            Op::FeqD {..} |
            Op::FltD {..} |
            Op::FleD {..} |
            Op::FcvtDW {..} |
            Op::FcvtDWu {..} |
            Op::FcvtDL {..} |
            Op::FcvtDLu {..} |
            Op::FmvDX {..} |
            Op::FmaddD {..} |
            Op::FmsubD {..} |
            Op::FnmsubD {..} |
            Op::FnmaddD {..} => self.emit_step_call(op),

            /* M-extension */
            Op::Mul { rd, rs1, rs2 } => self.emit_mul(rd, rs1, rs2),
            Op::Mulh { rd, rs1, rs2 } => self.emit_mulh(rd, rs1, rs2, false),
            Op::Mulhsu { rd, rs1, rs2 } => self.emit_mulhsu(rd, rs1, rs2),
            Op::Mulhu { rd, rs1, rs2 } => self.emit_mulh(rd, rs1, rs2, true),
            Op::Div { rd, rs1, rs2 } => self.emit_div(rd, rs1, rs2, false, false),
            Op::Divu { rd, rs1, rs2 } => self.emit_div(rd, rs1, rs2, true, false),
            Op::Rem { rd, rs1, rs2 } => self.emit_div(rd, rs1, rs2, false, true),
            Op::Remu { rd, rs1, rs2 } => self.emit_div(rd, rs1, rs2, true, true),
            Op::Mulw { rd, rs1, rs2 } => self.emit_mulw(rd, rs1, rs2),
            Op::Divw { rd, rs1, rs2 } => self.emit_divw(rd, rs1, rs2, false, false),
            Op::Divuw { rd, rs1, rs2 } => self.emit_divw(rd, rs1, rs2, true, false),
            Op::Remw { rd, rs1, rs2 } => self.emit_divw(rd, rs1, rs2, false, true),
            Op::Remuw { rd, rs1, rs2 } => self.emit_divw(rd, rs1, rs2, true, true),

            /* A-extension */
            Op::LrW {..} |
            Op::LrD {..} |
            Op::ScW {..} |
            Op::ScD {..} |
            Op::AmoswapW {..} |
            Op::AmoswapD {..} |
            Op::AmoaddW {..} |
            Op::AmoaddD {..} |
            Op::AmoandW {..} |
            Op::AmoandD {..} |
            Op::AmoorW {..} |
            Op::AmoorD {..} |
            Op::AmoxorW {..} |
            Op::AmoxorD {..} |
            Op::AmominW {..} |
            Op::AmominD {..} |
            Op::AmomaxW {..} |
            Op::AmomaxD {..} |
            Op::AmominuW {..} |
            Op::AmominuD {..} |
            Op::AmomaxuW {..} |
            Op::AmomaxuD {..} => self.emit_step_call(op),

            /* Privileged */
            Op::Sret => self.emit_step_call(op),
            Op::Wfi => (),
            Op::SfenceVma {..} => self.emit_step_call(op),
        }
    }

    pub fn compile(&mut self, block: (&[(Op, bool)], u64, u64)) {
        // Compilation requires Op to be 'static
        let opblock = block.0;

        // Pre-adjust PC
        self.emit(Add(Mem(memory_of_pc()), Imm((block.2 - block.1) as i64)));

        // Increase instret
        let mem_of_instret = (Register::RBP + offset_of!(Context, instret) as i32).qword();
        self.emit(Add(Mem(mem_of_instret), Imm(opblock.len() as i64)));

        // Increase minstret, the immediate is a placeholder and will be patched later
        // Note minstret is not precisely tracked in case of exception
        let mem_of_minstret = (Register::RBP + offset_of!(Context, minstret) as i32).qword();
        self.emit(Add(Mem(mem_of_minstret), Imm(0x77777777)));
        let fixup = self.len;

        let mut cur_pc = block.1;

        for i in 0..opblock.len() {
            if cfg!(not(feature = "fast")) {
                let cache_line_size = 1 << super::interp::CACHE_LINE_LOG2_SIZE;
                if cur_pc & (cache_line_size - 1) == 0 || cur_pc & (cache_line_size - 1) == cache_line_size - 2 {
                    self.emit_icache_access(block.2 - cur_pc);
                }
            }
            self.pc_rel = block.2 - cur_pc;
            cur_pc += if opblock[i].1 { 2 } else { 4 };

            let op = &opblock[i].0;
            self.i_rel = opblock.len() - i;
            if let Op::Auipc { rd, imm } = op {
                self.emit_op(&Op::Auipc { rd: *rd, imm: imm - (block.2 - cur_pc) as i32 });
            } else {
                if self.interp {
                    self.emit_step_call(op)
                } else {
                    self.emit_op(op);
                }
            }

            if cfg!(not(feature = "fast")) || (cfg!(not(feature = "thread")) && i == opblock.len() - 1) {
                self.emit_helper_call(helper_yield);
            }
        }

        // Epilogue
        self.emit_interrupt_check();
        self.emit_chain_tail();

        // Patch up minstret
        self.buffer[fixup-4..fixup].copy_from_slice(&self.minstret.to_le_bytes());

        if crate::get_flags().disassemble {
            let pc_offset = self.buffer.as_ptr() as usize;
            let mut pc = 0;
            while pc < self.len {
                let mut pc_next = pc;
                let op = crate::x86::decode(&mut || {
                    let ret = self.buffer[pc_next];
                    pc_next += 1;
                    ret
                });
                crate::x86::disasm::print_instr((pc_offset + pc) as u64, &self.buffer[pc..pc_next], &op);
                pc = pc_next;
            }
        }
    }
}
